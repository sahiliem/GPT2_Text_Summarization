{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahiliem/GPT2_Text_Summarization/blob/main/GPT2_for_text_sumarization1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHIsu1ze14J"
      },
      "source": [
        "# Let's Install the Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--VgC7Mfe1eG",
        "outputId": "b0cc9e37-020a-4a60-caf4-932f62a8e11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 136 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 231 kB 55.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 256 kB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.8 MB 413 kB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 47.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 192 kB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 46.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 52.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 52.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 995 kB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.3 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
            "Reason for being yanked: Segfaults\u001b[0m\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
            "Reason for being yanked: grpcio 1.45.0 was yanked\u001b[0m\n",
            "\u001b[?25h  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for polling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "nbclient 0.6.3 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install layer --upgrade -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxNNjwinfQFB"
      },
      "outputs": [],
      "source": [
        "from layer.decorators import dataset, model,resources, pip_requirements, fabric\n",
        "from layer import Model\n",
        "import layer\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3TNqIaViq6w"
      },
      "source": [
        "## Getting started with Layer:\n",
        "- Login to Layer Console\n",
        "- Initialize the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0pK0QY9fTKV"
      },
      "outputs": [],
      "source": [
        "# Login to Layer:\n",
        "layer.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JObyccnfeZO",
        "outputId": "5fa1dafd-8fca-4c17-837d-0cac3b41560f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Project(name='GPT2_text_summarization', raw_datasets=[], derived_datasets=[], models=[], path=PosixPath('.'), project_files_hash='', readme='', account=Account(id=UUID('c9442765-3fe4-4729-a7e4-d3fc9b07726b'), name='aymane_hachcham'), _id=UUID('f29c025a-0d92-4913-94ff-035d4de50df7'), functions=[])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Initialize the project:\n",
        "layer.init('GPT2_text_summarization')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXg4akFYjWMo"
      },
      "source": [
        "## Process and Load the Dataset to Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBoRT5NEsxG",
        "outputId": "451b27a3-74ee-4f49-f2e3-3959b0dcc5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cexb-rRzjGSn"
      },
      "outputs": [],
      "source": [
        "# Load the dataset:\n",
        "data_path = '/content/drive/MyDrive/GPT2/Dataset/Reviews.csv'\n",
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYapNeyKjpmE",
        "outputId": "60ba793a-061d-4243-bc6c-fef3f2bb91aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ]
        }
      ],
      "source": [
        "reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "Tg-V9jiWj5eQ",
        "outputId": "070e203c-38c5-4e74-dfb5-c075166bd270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98c807d2-b334-4a7e-8a32-7d4e92c63db9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98c807d2-b334-4a7e-8a32-7d4e92c63db9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98c807d2-b334-4a7e-8a32-7d4e92c63db9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98c807d2-b334-4a7e-8a32-7d4e92c63db9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing and Cleaning"
      ],
      "metadata": {
        "id": "g2QuK11-3zAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values:\n",
        "print(reviews.isna().sum())\n",
        "\n",
        "# Remove null values:\n",
        "reviews.dropna(inplace=True)\n",
        "\n",
        "# Combining the two columns review and summary:\n",
        "reviews['training'] = reviews['Text']  + 'TL;DR' + reviews['Summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziEy4_sk3x-P",
        "outputId": "bfa84c63-ce86-42eb-c4a5-4ebb75b7258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               16\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews[:1500].info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3204Ryx4GfR",
        "outputId": "5cb4ada3-39b6-40c1-d5eb-2c586204812e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1500 entries, 0 to 1499\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      1500 non-null   int64 \n",
            " 1   ProductId               1500 non-null   object\n",
            " 2   UserId                  1500 non-null   object\n",
            " 3   ProfileName             1500 non-null   object\n",
            " 4   HelpfulnessNumerator    1500 non-null   int64 \n",
            " 5   HelpfulnessDenominator  1500 non-null   int64 \n",
            " 6   Score                   1500 non-null   int64 \n",
            " 7   Time                    1500 non-null   int64 \n",
            " 8   Summary                 1500 non-null   object\n",
            " 9   Text                    1500 non-null   object\n",
            " 10  training                1500 non-null   object\n",
            "dtypes: int64(5), object(6)\n",
            "memory usage: 140.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We take 5000 rows from the whole data. So can avoid GPU out of memory:\n",
        "reviews = reviews[['Summary','Text','training']][:5000]"
      ],
      "metadata": {
        "id": "oXGideUQ4fUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459,
          "referenced_widgets": [
            "9a6f36bd24de43b4a5f009772fd3be75",
            "24c436b40549400393e5dde832183321"
          ]
        },
        "id": "iNAF0Jp7j6pB",
        "outputId": "fbec78b0-234c-4555-e680-fb12ffe5aa2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a6f36bd24de43b4a5f009772fd3be75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Summary  \\\n",
              "0                                 Good Quality Dog Food   \n",
              "1                                     Not as Advertised   \n",
              "2                                 \"Delight\" says it all   \n",
              "3                                        Cough Medicine   \n",
              "4                                           Great taffy   \n",
              "...                                                 ...   \n",
              "4995                 The cavemen must have been wealthy   \n",
              "4996  These cookies need work; you can make your own...   \n",
              "4997                        Okay in a pinch - not great   \n",
              "4998  they are good (except for the \"rainforest\" fla...   \n",
              "4999                               Great Healthy Snack!   \n",
              "\n",
              "                                                   Text  \\\n",
              "0     I have bought several of the Vitality canned d...   \n",
              "1     Product arrived labeled as Jumbo Salted Peanut...   \n",
              "2     This is a confection that has been around a fe...   \n",
              "3     If you are looking for the secret ingredient i...   \n",
              "4     Great taffy at a great price.  There was a wid...   \n",
              "...                                                 ...   \n",
              "4995  I really wanted to like these.<br /><br />Firs...   \n",
              "4996  I was not impressed with these cookies when I ...   \n",
              "4997  The cookies came sealed and seem to be high qu...   \n",
              "4998  These taste very good, but aren't like the BES...   \n",
              "4999  I love these cookies. I am on the paleo diet r...   \n",
              "\n",
              "                                               training  \n",
              "0     I have bought several of the Vitality canned d...  \n",
              "1     Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2     This is a confection that has been around a fe...  \n",
              "3     If you are looking for the secret ingredient i...  \n",
              "4     Great taffy at a great price.  There was a wid...  \n",
              "...                                                 ...  \n",
              "4995  I really wanted to like these.<br /><br />Firs...  \n",
              "4996  I was not impressed with these cookies when I ...  \n",
              "4997  The cookies came sealed and seem to be high qu...  \n",
              "4998  These taste very good, but aren't like the BES...  \n",
              "4999  I love these cookies. I am on the paleo diet r...  \n",
              "\n",
              "[5000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91b21f6e-0932-4250-b257-0056bce7203a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>training</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>The cavemen must have been wealthy</td>\n",
              "      <td>I really wanted to like these.&lt;br /&gt;&lt;br /&gt;Firs...</td>\n",
              "      <td>I really wanted to like these.&lt;br /&gt;&lt;br /&gt;Firs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>These cookies need work; you can make your own...</td>\n",
              "      <td>I was not impressed with these cookies when I ...</td>\n",
              "      <td>I was not impressed with these cookies when I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Okay in a pinch - not great</td>\n",
              "      <td>The cookies came sealed and seem to be high qu...</td>\n",
              "      <td>The cookies came sealed and seem to be high qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>they are good (except for the \"rainforest\" fla...</td>\n",
              "      <td>These taste very good, but aren't like the BES...</td>\n",
              "      <td>These taste very good, but aren't like the BES...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Great Healthy Snack!</td>\n",
              "      <td>I love these cookies. I am on the paleo diet r...</td>\n",
              "      <td>I love these cookies. I am on the paleo diet r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91b21f6e-0932-4250-b257-0056bce7203a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91b21f6e-0932-4250-b257-0056bce7203a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91b21f6e-0932-4250-b257-0056bce7203a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Save the dataset to Layer:\n",
        "@dataset('amazon_reviews')\n",
        "@resources(data_path)\n",
        "def read_reviews():\n",
        "    df = pd.read_csv(data_path) \n",
        "    # Remove null values:\n",
        "    df.dropna(inplace=True)  \n",
        "    # Combining the two columns review and summary:\n",
        "    df['training'] = df['Text'] + 'TL;DR' + df['Summary'] \n",
        "    df = df[['Summary','Text','training']][:5000]\n",
        "    return df\n",
        "\n",
        "read_reviews()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DJiT3EUoFTY",
        "outputId": "c45e6d14-132e-4abf-cf70-73b972663873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.1608"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# Take the average length of the reviews:\n",
        "\n",
        "sum_all_tokens = sum([len(review.split()) for review in reviews['training']])\n",
        "avg_length = sum_all_tokens / len(reviews['training'])\n",
        "avg_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8tAEEuPpYdZ"
      },
      "source": [
        "Since the average instance length in words is 80, we can assume that a max length of 150 will cover most of the instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzPSIGo2oXzd"
      },
      "outputs": [],
      "source": [
        "max_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['training']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkrm41AvlUJe",
        "outputId": "1f07ff20-9bd6-465b-fc3e-7272f987c59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I have bought several of the Vitality canned d...\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...\n",
              "2       This is a confection that has been around a fe...\n",
              "3       If you are looking for the secret ingredient i...\n",
              "4       Great taffy at a great price.  There was a wid...\n",
              "                              ...                        \n",
              "4995    I really wanted to like these.<br /><br />Firs...\n",
              "4996    I was not impressed with these cookies when I ...\n",
              "4997    The cookies came sealed and seem to be high qu...\n",
              "4998    These taste very good, but aren't like the BES...\n",
              "4999    I love these cookies. I am on the paleo diet r...\n",
              "Name: training, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIa0VkL1p0Fq"
      },
      "source": [
        "## Load the Model and the Tokenizer from Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6V62hIHpgg4"
      },
      "outputs": [],
      "source": [
        "@model(\"gpt2\")\n",
        "@fabric(\"f-medium\")\n",
        "@pip_requirements(packages=[\"torch\",\"transformers\",\"sentencepiece\"])\n",
        "def build_tokenizer():\n",
        "    from transformers import AutoTokenizer\n",
        "    # Load tokenizer from Hugging face\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    return tokenizer\n",
        "\n",
        "@model(\"gpt2\")\n",
        "@pip_requirements(packages=[\"torch\",\"transformers\",\"sentencepiece\"])\n",
        "def build_model():\n",
        "    from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "    from torch import cuda\n",
        "    import torch\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from transformers import AutoModelWithLMHead\n",
        "    import torch.optim as optim\n",
        "    \n",
        "    parameters={\n",
        "        \"BATCH_SIZE\":32,          \n",
        "        \"EPOCHS\":10,              \n",
        "        \"LEARNING_RATE\":3e-4,          \n",
        "        \"MAX_SOURCE_TEXT_LENGTH\":150,   \n",
        "        \"MAX_TARGET_TEXT_LENGTH\":150\n",
        "    }\n",
        "\n",
        "    # Log parameters to Layer\n",
        "    layer.log(parameters)\n",
        "  \n",
        "\n",
        "    # Load pretrained model from Hugging face\n",
        "    model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhdmyoJYuDwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "83cd9053cff64e5a835d5c0ffd613a7a",
            "e1cd5c8d52764073a2f9b27affecf18d"
          ]
        },
        "outputId": "4a9e5fe6-877f-43c3-c1e6-21930f583a0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83cd9053cff64e5a835d5c0ffd613a7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Starting setup of dependencies...\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Successfully logged into https://app.layer.ai\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Downloading execution artifacts model-training--layer2022040715233796120000001d/c9442765-3fe4-4729-a7e4-d3fc9b07726b/9e3a58a5-7c08-410d-b005-5bd2435da13a/gpt2-train.tgz to ~/source\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Creating directory ~/source\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Place __init__.py in ~/source\n",
            "\u001b[0;33m13:07:47 \u001b[1;32mgpt2\u001b[0m: Download binary(c9442765-3fe4-4729-a7e4-d3fc9b07726b/9e3a58a5-7c08-410d-b005-5bd2435da13a/gpt2-train.tgz) to temp directory\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Binary archive gpt2-train.tgz downloaded and extracted to ~/source successfully\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Execution artifacts model-training--layer2022040715233796120000001d/c9442765-3fe4-4729-a7e4-d3fc9b07726b/9e3a58a5-7c08-410d-b005-5bd2435da13a/gpt2-train.tgz downloaded successfully to ~/source\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Installing python dependencies from ~/source/requirements.txt\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: torch in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 1)) (1.9.0.post2)\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: transformers in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from -r /root/source/requirements.txt (line 2)) (4.18.0)\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Collecting sentencepiece\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m:   Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 41.1 MB/s eta 0:00:00\n",
            "\u001b[0;33m13:07:48 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: typing-extensions in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from torch->-r /root/source/requirements.txt (line 1)) (3.10.0.2)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (0.12.1)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (2022.4.24)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: requests in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (2.27.1)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: importlib-metadata in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (4.11.3)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (0.5.1)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: sacremoses in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (0.0.53)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (4.64.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: filelock in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (3.6.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (1.19.5)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (21.3)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from transformers->-r /root/source/requirements.txt (line 2)) (6.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from packaging>=20.0->transformers->-r /root/source/requirements.txt (line 2)) (3.0.8)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from importlib-metadata->transformers->-r /root/source/requirements.txt (line 2)) (3.8.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from requests->transformers->-r /root/source/requirements.txt (line 2)) (3.3)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from requests->transformers->-r /root/source/requirements.txt (line 2)) (2021.10.8)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from requests->transformers->-r /root/source/requirements.txt (line 2)) (1.26.9)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from requests->transformers->-r /root/source/requirements.txt (line 2)) (2.0.12)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: joblib in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from sacremoses->transformers->-r /root/source/requirements.txt (line 2)) (1.1.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: click in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from sacremoses->transformers->-r /root/source/requirements.txt (line 2)) (8.1.3)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Requirement already satisfied: six in /opt/conda/envs/python_3_7/lib/python3.7/site-packages (from sacremoses->transformers->-r /root/source/requirements.txt (line 2)) (1.15.0)\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Installing collected packages: sentencepiece\n",
            "\u001b[0;33m13:07:49 \u001b[1;32mgpt2\u001b[0m: Successfully installed sentencepiece-0.1.96\n",
            "\u001b[0;33m13:07:50 \u001b[1;32mgpt2\u001b[0m: Python dependencies from ~/source/requirements.txt installed successfully\n",
            "\u001b[0;33m13:07:51 \u001b[1;32mgpt2\u001b[0m: Starting job.\n",
            "\u001b[0;33m13:07:51 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:51 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:51 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:52 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:52 \u001b[1;32mgpt2\u001b[0m: Importing user code(gpt2.pkl) from ~/source\n",
            "\u001b[0;33m13:07:52 \u001b[1;32mgpt2\u001b[0m: train_model_func function imported successfully\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Injecting the dependencies\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Annotations: {}\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Entity dependencies: {'models': {}, 'raw_datasets': {}, 'derived_datasets': {}, 'context': None, 'train': None}\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Injected dependencies successfully: {}\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Executing the train_model_func\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Downloading resources\n",
            "\u001b[0;33m13:07:53 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Creating converter from 7 to 5\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Creating converter from 5 to 7\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Creating converter from 7 to 5\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Creating converter from 5 to 7\n",
            "\u001b[0;33m13:07:54 \u001b[1;32mgpt2\u001b[0m: Using selector: EpollSelector\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m: Attempting to acquire lock 140129902315280 on /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51.lock\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m: Lock 140129902315280 acquired on /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51.lock\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m: /opt/conda/envs/python_3_7/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:911: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m:   FutureWarning,\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m: Attempting to release lock 140129902315280 on /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51.lock\n",
            "\u001b[0;33m13:07:55 \u001b[1;32mgpt2\u001b[0m: Lock 140129902315280 released on /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51.lock\n",
            "\u001b[0;33m13:07:56 \u001b[1;32mgpt2\u001b[0m: Attempting to acquire lock 140129822891728 on /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925.lock\n",
            "\u001b[0;33m13:07:56 \u001b[1;32mgpt2\u001b[0m: Lock 140129822891728 acquired on /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925.lock\n",
            "Downloading: 100%|██████████| 665/665 [00:00<00:00, 673kB/s]\n",
            "\u001b[0;33m13:08:03 \u001b[1;32mgpt2\u001b[0m: Attempting to release lock 140129822891728 on /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925.lock\n",
            "\u001b[0;33m13:08:03 \u001b[1;32mgpt2\u001b[0m: Lock 140129822891728 released on /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925.lock\n",
            "\u001b[0;33m13:08:06 \u001b[1;32mgpt2\u001b[0m: Executed train_model_func successfully\n",
            "\u001b[0;33m13:08:06 \u001b[1;32mgpt2\u001b[0m: Saving model artifact GPT2LMHeadModel(_  (transformer): GPT2Model(_    (wte): Embedding(50257, 768)_    (wpe): Embedding(1024, 768)_    (drop): Dropout(p=0.1, inplace=False)_    (h): ModuleList(_      (0): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (1): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (2): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (3): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (4): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (5): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (6): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (7): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (8): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (9): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (10): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (11): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_    )_    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_  )_  (lm_head): Linear(in_features=768, out_features=50257, bias=False)_) to model registry\n",
            "\u001b[0;33m13:08:06 \u001b[1;32mgpt2\u001b[0m: Matching flavor: <layer.mlmodels.flavors.flavor.HuggingFaceModelFlavor object at 0x7f72d46bc510>\n",
            "\u001b[0;33m13:08:06 \u001b[1;32mgpt2\u001b[0m: flavor name: HuggingFaceModelFlavor, proto flavor: 13\n",
            "\u001b[0;33m13:08:07 \u001b[1;32mgpt2\u001b[0m: Storing given model GPT2LMHeadModel(_  (transformer): GPT2Model(_    (wte): Embedding(50257, 768)_    (wpe): Embedding(1024, 768)_    (drop): Dropout(p=0.1, inplace=False)_    (h): ModuleList(_      (0): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (1): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (2): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (3): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (4): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (5): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (6): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (7): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (8): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (9): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (10): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (11): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_    )_    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_  )_  (lm_head): Linear(in_features=768, out_features=50257, bias=False)_) with definition ModelDefinition{model_name:gpt2model_train_id:ec37254b-7645-4964-90b6-e15cd97c0674proto_flavor:13s3_path:bucket: \"model-catalog--layer20220407152331648300000019\"_key: \"c9442765-3fe4-4729-a7e4-d3fc9b07726b/ec37254b-7645-4964-90b6-e15cd97c0674/\"_}\n",
            "\u001b[0;33m13:08:07 \u001b[1;32mgpt2\u001b[0m: Saving user model gpt2(GPT2LMHeadModel(_  (transformer): GPT2Model(_    (wte): Embedding(50257, 768)_    (wpe): Embedding(1024, 768)_    (drop): Dropout(p=0.1, inplace=False)_    (h): ModuleList(_      (0): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (1): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (2): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (3): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (4): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (5): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (6): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (7): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (8): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (9): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (10): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (11): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_    )_    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_  )_  (lm_head): Linear(in_features=768, out_features=50257, bias=False)_))\n",
            "\u001b[0;33m13:08:07 \u001b[1;32mgpt2\u001b[0m: Writing model ModelDefinition{model_name:gpt2model_train_id:ec37254b-7645-4964-90b6-e15cd97c0674proto_flavor:13s3_path:bucket: \"model-catalog--layer20220407152331648300000019\"_key: \"c9442765-3fe4-4729-a7e4-d3fc9b07726b/ec37254b-7645-4964-90b6-e15cd97c0674/\"_}\n",
            "\u001b[0;33m13:08:11 \u001b[1;32mgpt2\u001b[0m: User model gpt2 saved successfully\n",
            "\u001b[0;33m13:08:11 \u001b[1;32mgpt2\u001b[0m: Saved model artifact GPT2LMHeadModel(_  (transformer): GPT2Model(_    (wte): Embedding(50257, 768)_    (wpe): Embedding(1024, 768)_    (drop): Dropout(p=0.1, inplace=False)_    (h): ModuleList(_      (0): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (1): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (2): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (3): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (4): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (5): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (6): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (7): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (8): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (9): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (10): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_      (11): GPT2Block(_        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (attn): GPT2Attention(_          (c_attn): Conv1D()_          (c_proj): Conv1D()_          (attn_dropout): Dropout(p=0.1, inplace=False)_          (resid_dropout): Dropout(p=0.1, inplace=False)_        )_        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_        (mlp): GPT2MLP(_          (c_fc): Conv1D()_          (c_proj): Conv1D()_          (act): NewGELUActivation()_          (dropout): Dropout(p=0.1, inplace=False)_        )_      )_    )_    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)_  )_  (lm_head): Linear(in_features=768, out_features=50257, bias=False)_) to model registry successfully\n",
            "Downloading: 100%|██████████| 523M/523M [00:07<00:00, 72.4MB/s]\n",
            "\u001b[0;33m13:08:12 \u001b[1;32mgpt2\u001b[0m: ['/opt/conda/envs/python_3_7/bin/python -X faulthandler -m pyruntime.model.train_executor 2>/proc/1/fd/2' exited with 0]\n",
            "\u001b[0;33m13:08:12 \u001b[1;32mgpt2\u001b[0m: Process exit code: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(project_name='GPT2_text_summarization')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "layer.run([build_tokenizer, build_model], debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMe1Xk1DuK0o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52,
          "referenced_widgets": [
            "3cbc96e557db4cb1a1bc520d4793c4cd",
            "f4cee74387194859a96f473b58e9f711"
          ]
        },
        "outputId": "7736fe95-9b05-495b-9906-536b7bf719da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cbc96e557db4cb1a1bc520d4793c4cd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "tokenizer = build_tokenizer()\n",
        "extra_length = len(tokenizer.encode(\" TL;DR \"))\n",
        " \n",
        "class GPT2ReviewDataset(Dataset):  \n",
        "    def __init__(self, tokenizer, reviews, max_len):\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.eos = self.tokenizer.eos_token\n",
        "        self.eos_id = self.tokenizer.eos_token_id\n",
        "        self.reviews = reviews\n",
        "        self.result = []\n",
        "\n",
        "        for review in self.reviews:\n",
        "            # Encode the text using tokenizer.encode(). We add EOS at the end\n",
        "            tokenized = self.tokenizer.encode(review + self.eos)\n",
        "            \n",
        "            # Padding/truncating the encoded sequence to max_len \n",
        "            padded = self.pad_truncate(tokenized)            \n",
        "\n",
        "            # Creating a tensor and adding to the result\n",
        "            self.result.append(torch.tensor(padded))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.result)\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.result[item]\n",
        "\n",
        "    def pad_truncate(self, name):\n",
        "        extra_length = 4\n",
        "        name_length = len(name) - extra_length\n",
        "        if name_length < self.max_len:\n",
        "            difference = self.max_len - name_length\n",
        "            result = name + [self.eos_id] * difference\n",
        "        elif name_length > self.max_len:\n",
        "            result = name[:self.max_len + 3]+[self.eos_id] \n",
        "        else:\n",
        "            result = name\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX0cW6MtGcO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94f5192-c85c-4001-9a32-e5b100c94f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "dataset = GPT2ReviewDataset(tokenizer, reviews['training'], max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKofMZWBG1a0"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset:\n",
        "  print(item)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjQrwTMNt93G",
        "outputId": "9eff1a82-4d72-43e0-a84e-92a9de7759f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   40,   423,  5839,  1811,   286,   262, 28476,   414, 32530,  3290,\n",
            "         2057,  3186,   290,   423,  1043,   606,   477,   284,   307,   286,\n",
            "          922,  3081,    13,   383,  1720,  3073,   517,   588,   257, 20798,\n",
            "          621,   257, 13686,  6174,   290,   340, 25760,  1365,    13,  2011,\n",
            "        45246,   318,   957, 17479,   290,   673,  5763,   689,   428,  1720,\n",
            "         1365,   621,   220,   749,    13, 14990,    26,  7707, 10248, 14156,\n",
            "         8532,  7318, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDf41ZdGG8iD"
      },
      "outputs": [],
      "source": [
        "# The training Loop:\n",
        "# @pip_requirements(packages=[\"transformers\",\"sentencepiece\"])\n",
        "# @fabric(\"f-gpu-small\")\n",
        "# @model(\"gpt2\")\n",
        "def train(model, optimizer, dl, epochs):    \n",
        "    for epoch in range(epochs):\n",
        "        for idx, batch in enumerate(dl):\n",
        "             with torch.set_grad_enabled(True):\n",
        "                optimizer.zero_grad()\n",
        "                batch = batch.to('cuda')\n",
        "                output = model(batch, labels=batch)\n",
        "                loss = output[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if idx % 50 == 0:\n",
        "                    print(\"loss: %f, %d\"%(loss, idx))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer.run([train])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "LnwhtUgb92mK",
        "outputId": "94dc26b5-1d17-4496-b6d7-dbe0d0ac161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConfigError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConfigError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-7e633df55b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/layer/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(functions, debug)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# run = layer.run([create_my_dataset], debug=True)  # Stream logs to console\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0m_ensure_all_functions_are_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mproject_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_project_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/layer/main.py\u001b[0m in \u001b[0;36m_ensure_all_functions_are_decorated\u001b[0;34m(functions)\u001b[0m\n\u001b[1;32m    460\u001b[0m             )\n\u001b[1;32m    461\u001b[0m         \u001b[0msettings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLayerSettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/layer/settings.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_asset_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             raise ConfigError(\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0;34m'Either @dataset(name=\"...\") or @model(name=\"...\") top level decorator '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;34m\"is required for each function. Add @dataset or @model decorator on top of existing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;34m\"decorators to run functions in Layer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConfigError\u001b[0m: Either @dataset(name=\"...\") or @model(name=\"...\") top level decorator is required for each function. Add @dataset or @model decorator on top of existing decorators to run functions in Layer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108,
          "referenced_widgets": [
            "b9b6e53ed80a4a11b5317995b170f040",
            "0753e0c6f74d414ea0113eeb4eaaca68"
          ]
        },
        "id": "c4VqgSe6Hrmk",
        "outputId": "b6628524-bf5e-4a1d-b551-8010f4e4879c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9b6e53ed80a4a11b5317995b170f040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:911: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Fz214sHysO"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(params = model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pPqpNzJHxDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d07fb4b-d99e-4dc3-e625-571cf68ad0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.198657, 0\n",
            "loss: 2.288299, 50\n"
          ]
        }
      ],
      "source": [
        "train(model=model, optimizer=optimizer, dl=dataloader, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX8TwnlkIyuJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def topk(probs, n=9):\n",
        "    # The scores are initially softmaxed to convert to probabilities\n",
        "    probs = torch.softmax(probs, dim= -1)\n",
        "    \n",
        "    # PyTorch has its own topk method, which we use here\n",
        "    tokensProb, topIx = torch.topk(probs, k=n)\n",
        "    \n",
        "    # The new selection pool (9 choices) is normalized\n",
        "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
        "\n",
        "    # Send to CPU for numpy handling\n",
        "    tokensProb = tokensProb.cpu().detach().numpy()\n",
        "\n",
        "    # Make a random choice from the pool based on the new prob distribution\n",
        "    choice = np.random.choice(n, 1, p = tokensProb)\n",
        "    tokenId = topIx[choice][0]\n",
        "\n",
        "    return int(tokenId)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcE0a2i2JshT"
      },
      "outputs": [],
      "source": [
        "def model_infer(model, tokenizer, review, max_length=15):\n",
        "    # Preprocess the init token (task designator)\n",
        "    review_encoded = tokenizer.encode(review)\n",
        "    result = review_encoded\n",
        "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to('cuda')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        # Feed the init token to the model\n",
        "        output = model(initial_input)\n",
        "\n",
        "        # Flatten the logits at the final time step\n",
        "        logits = output.logits[0,-1]\n",
        "\n",
        "        # Make a top-k choice and append to the result\n",
        "        result.append(topk(logits))\n",
        "\n",
        "        # For max_length times:\n",
        "        for _ in range(max_length):\n",
        "            # Feed the current sequence to the model and make a choice\n",
        "            input = torch.tensor(result).unsqueeze(0).to('cuda')\n",
        "            output = model(input)\n",
        "            logits = output.logits[0,-1]\n",
        "            res_id = topk(logits)\n",
        "\n",
        "            # If the chosen token is EOS, return the result\n",
        "            if res_id == tokenizer.eos_token_id:\n",
        "                return tokenizer.decode(result)\n",
        "            else: # Append to the sequence \n",
        "                result.append(res_id)\n",
        "\n",
        "    # IF no EOS is generated, return after the max_len\n",
        "    return tokenizer.decode(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT67LC2zJ1gB"
      },
      "outputs": [],
      "source": [
        "sample_reviews = reviews['training'].sample(n=1, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"My local coffee shop has me addicted to their 20 oz vanilla chai lattes. At $3.90 a pop I was spending a lot of money.  I asked what brand they used, need nutritional information, of course!  They told me it was Big Train Chai Vanilla.<br />It's important to follow the directions on the can.  I made mine with just milk with a yucky result.  Use the water with a little milk as there is milk powder in the mix.<br /><br />WARNING:It's addicting!!!\""
      ],
      "metadata": {
        "id": "cpbzRrzdGpdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = [model_infer(model, tokenizer, review).strip() for review in sample_reviews]"
      ],
      "metadata": {
        "id": "AUlyWEEJH46D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Cau-zlIJSO",
        "outputId": "69e4e494-5f16-4d38-fc7b-8fc648791fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"No Microwave Directions on Box!TL;DRI look forward to cooking in the microwave...means no spattered stove to clean! BIG SURPRISE - no microwave directions. Well this will be a noble experiment because it will be microwaved! Called Miss Betty Crocker @ General Mills and they don't supply microwaved directions either. So wish me luck as I experiment!<br /><br />UPDATE: Found Microwave directions on web BUT you still have to experiment :(<br /><br />MICROWAVE DIRECTIONS<br />1. Crumble 1 lb lean ground beef into 3-qt microwavable casserole or bowl. Microwave uncovered on High 3 to 5 minutes, breaking up beef after 3 minutes, until brown; drain.<br />2. Stir in sauce mix, 2-2/3 cups boiling water, 1 cup milk and uncooked potatoes.<br />3. Microwave uncovered on High 14 to 21 minutes, stirring every 7 minutes, until potatoes are tender (sauce will thicken as it stands). Dish will be hot. Meanwhile, stir 1/4 cup milk and toping mix in bowl 30 seconds; set aside.<br />4. Pour topping over beef mixture. (If topping is too thick to pour, stir in an additional 1/2 to 1 tsp milk.)<br /><br />***High altitude microwave (3500-6500 ft): increase boiling water to 3 cups and last microwave time to 18-25 min.<|endoftext|>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "1xVO16awKNFW",
        "outputId": "c624fe33-dcd9-40d0-d519-c5b8e576dd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I look forward to cooking in the microwave...means no spattered stove to clean! BIG SURPRISE - no microwave directions. Well this will be a noble experiment because it will be microwaved! Called Miss Betty Crocker @ General Mills and they don't supply microwaved directions either. So wish me luck as I experiment!<br /><br />UPDATE: Found Microwave directions on web BUT you still have to experiment :(<br /><br />MICROWAVE DIRECTIONS<br />1. Crumble 1 lb lean ground beef into 3-qt microwavable casserole or bowl. Microwave uncovered on High 3 to 5 minutes, breaking up beef after 3 minutes, until brown; drain.<br />2. Stir in sauce mix, 2-2/3 cups boiling water, 1 cup milk and uncooked potatoes.<br />3. Microwave uncovered on High 14 to 21 minutes, stirring every 7 minutes, until potatoes are tender (sauce will thicken as it stands). Dish will be hot. Meanwhile, stir 1/4 cup milk and toping mix in bowl 30 seconds; set aside.<br />4. Pour topping over beef mixture. (If topping is too thick to pour, stir in an additional 1/2 to 1 tsp milk.)<br /><br />***High altitude microwave (3500-6500 ft): increase boiling water to 3 cups and last microwave time to 18-25 min.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f08631d7a8e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-46749fd08ed0>\u001b[0m in \u001b[0;36mmodel_infer\u001b[0;34m(model, tokenizer, review, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mres_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# If the chosen token is EOS, return the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-344bebb3afc9>\u001b[0m in \u001b[0;36mtopk\u001b[0;34m(probs, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Send to CPU for numpy handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtokensProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokensProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Make a random choice from the pool based on the new prob distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for review in sample_reviews:\n",
        "    summaries = set()\n",
        "    print(review)\n",
        "    while len(summaries) < 3:\n",
        "        summary = model_infer(model, tokenizer, review).strip()\n",
        "        if summary not in summaries:\n",
        "            summaries.add(summary)\n",
        "    print(\"Summaries: \"+ str(summaries) +\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJE65-78Kz08"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a6f36bd24de43b4a5f009772fd3be75": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_24c436b40549400393e5dde832183321",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✅  amazon_reviews       \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:14\u001b[0m\u001b[39m]\u001b[0m                                         \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=964541;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/datasets/amazon_reviews\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/datasets/amazon_reviews\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  amazon_reviews       <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:14</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                         \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/datasets/amazon_reviews\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/datasets/amazon_reviews</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "24c436b40549400393e5dde832183321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83cd9053cff64e5a835d5c0ffd613a7a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e1cd5c8d52764073a2f9b27affecf18d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32m⠇ \u001b[0m  gpt2                 \u001b[38;2;127;127;134m━\u001b[0m\u001b[38;2;145;145;152m━\u001b[0m\u001b[38;2;157;157;164m━\u001b[0m\u001b[38;2;161;161;169m━\u001b[0m\u001b[38;2;157;157;164m━\u001b[0m\u001b[38;2;145;145;152m━\u001b[0m\u001b[38;2;127;127;134m━\u001b[0m\u001b[38;2;105;105;110m━\u001b[0m\u001b[38;2;80;80;84m━\u001b[0m\u001b[38;2;55;55;58m━\u001b[0m PENDING \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m-:--:--\u001b[0m\u001b[39m]\u001b[0m                                 \n✅  gpt2                 \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:29\u001b[0m\u001b[39m]\u001b[0m                                    \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=194090;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=16.1\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=16.1\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠇ </span>  gpt2                 <span style=\"color: #7f7f86; text-decoration-color: #7f7f86\">━</span><span style=\"color: #919198; text-decoration-color: #919198\">━</span><span style=\"color: #9d9da4; text-decoration-color: #9d9da4\">━</span><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9\">━</span><span style=\"color: #9d9da4; text-decoration-color: #9d9da4\">━</span><span style=\"color: #919198; text-decoration-color: #919198\">━</span><span style=\"color: #7f7f86; text-decoration-color: #7f7f86\">━</span><span style=\"color: #69696e; text-decoration-color: #69696e\">━</span><span style=\"color: #505054; text-decoration-color: #505054\">━</span><span style=\"color: #37373a; text-decoration-color: #37373a\">━</span> PENDING <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">-:--:--</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                 \n✅  gpt2                 <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:29</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                    \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=16.1\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=16.1</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "e1cd5c8d52764073a2f9b27affecf18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbc96e557db4cb1a1bc520d4793c4cd": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f4cee74387194859a96f473b58e9f711",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✅  gpt2                 \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:06\u001b[0m\u001b[39m]\u001b[0m                                       \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=466227;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=17.None\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=17.None\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2                 <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:06</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                       \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=17.None\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=17.None</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f4cee74387194859a96f473b58e9f711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b6e53ed80a4a11b5317995b170f040": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0753e0c6f74d414ea0113eeb4eaaca68",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✅  gpt2                 \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:36\u001b[0m\u001b[39m]\u001b[0m                                       \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=409778;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=18.None\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=18.None\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2                 <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:36</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                       \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=18.None\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2?v=18.None</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0753e0c6f74d414ea0113eeb4eaaca68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}